{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:07:34.203001Z",
     "start_time": "2019-02-28T17:07:34.199035Z"
    }
   },
   "outputs": [],
   "source": [
    "SRC='/home/jmurga/mkt/201903/scripts/src'\n",
    "DATA='/home/jmurga/mkt/201903/rawData/humans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:07:32.555395Z",
     "start_time": "2019-02-28T17:07:32.501542Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import allel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyfaidx as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, SRC)\n",
    "from reverseComplement import reverseComplement\n",
    "from degenerancy import degenerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Human genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T09:55:47.492822Z",
     "start_time": "2019-03-06T09:55:47.484081Z"
    },
    "hidden": true
   },
   "source": [
    "To execute bash code we created a snippets through nbextensions containing the following paths in order to avoid copy and paste cells. %%bash magic do not recognize previous variables. Adding mkdir command to create necesary paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "DATA='/home/jmurga/mkt/201903/rawData/humans/annotations'\n",
    "BASIC='/home/jmurga/mkt/201903/rawData/humans/annotations/basicAnnotation'\n",
    "CDS='/home/jmurga/mkt/201903/rawData/humans/annotations/cds'\n",
    "GENES='/home/jmurga/mkt/201903/rawData/humans/annotations/genes'\n",
    "TEMPORAL='/home/jmurga/mkt/201903/rawData/humans/annotations/tmp'\n",
    "ALLELEFREQ='/home/jmurga/mkt/201903/rawData/humans/alleleFrequencies'\n",
    "\n",
    "mkdir -p ${DATA}\n",
    "mkdir -p ${BASIC}\n",
    "mkdir -p ${CDS}\n",
    "mkdir -p ${GENES}\n",
    "mkdir -p ${TEMPORAL}\n",
    "mkdir -p ${ALLELEFREQ}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Download [gencode annotation](https://www.gencodegenes.org/human/release_27lift37.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T09:58:30.923202Z",
     "start_time": "2019-03-06T09:58:17.481212Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "DATA='/home/jmurga/mkt/201903/rawData/humans'\n",
    "ANNOTATIONS='/home/jmurga/mkt/201903/rawData/humans/annotations'\n",
    "EXPRESSION='/home/jmurga/mkt/201903/rawData/humans/expression'\n",
    "\n",
    "cd ${ANNOTATIONS}\n",
    "# Gencode annotation\n",
    "wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/GRCh37_mapping/gencode.v27lift37.basic.annotation.gff3.gz\n",
    "gunzip *.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Download reference fastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "DATA='/home/jmurga/mkt/201903/rawData/humans'\n",
    "FASTAS='/home/jmurga/mkt/201903/rawData/humans/fastas/'\n",
    "mkdir - p ${FASTAS}\n",
    "mkdir - p ${FASTAS}/ref\n",
    "\n",
    "cd ${FASTAS}/ref\n",
    "\n",
    "wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.gz \n",
    "wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.fai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = px.Fasta('/home/jmurga/mkt/201903/rawData/humans/fastas/ref/human_g1k_v37.fasta',duplicate_action='first',sequence_always_upper=True,read_long_names=True)\n",
    "\n",
    "samples = list(file.keys())[0:24]\n",
    "\n",
    "for nchr in range(0,len(samples),1):\n",
    "    print('>chr' + samples[nchr].split(' ')[0])\n",
    "    f = open('/home/jmurga/mkt/201903/rawData/humans/fastas/ref/chr' + samples[nchr].split(' ')[0] + '.fa' , 'w')\n",
    "    tmp = file[samples[nchr]][:].seq\n",
    "    f.write('>chr' + samples[nchr].split(' ')[0] + '\\n' + file[samples[nchr]][:].seq)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "rm ${FASTA}/ref/human_g1k*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Parsing and cleaning gencode annotation to execute all operations by chr\n",
    "Operate by chr is faster due to grep on smaller files. Each folder contain an specific file foreach chromosome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T10:00:35.284667Z",
     "start_time": "2019-03-06T09:59:09.831022Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ANNOTATIONS='/home/jmurga/mkt/201903/rawData/humans/annotations'\n",
    "BASIC='/home/jmurga/mkt/201903/rawData/humans/annotations/basicAnnotation'\n",
    "CDS='/home/jmurga/mkt/201903/rawData/humans/annotations/cds'\n",
    "GENES='/home/jmurga/mkt/201903/rawData/humans/annotations/genes'\n",
    "\n",
    "mkdir -p ${BASIC}\n",
    "mkdir -p ${CDS}\n",
    "mkdir -p ${GENES}\n",
    "\n",
    "# Deleting commented lines\n",
    "sed -i '/^#/ d' ${ANNOTATIONS}/gencode.v27lift37.basic.annotation.gff3\n",
    "# Extract genes information\n",
    "grep -P \"\\tgene\\t\" ${ANNOTATIONS}/gencode.v27lift37.basic.annotation.gff3 | grep -vP \"chrM\\t\" > ${ANNOTATIONS}/gencode.v27lift37.genes.gff3\n",
    "# Extract CDS information. Only protein coding genes\n",
    "grep -P \"\\tCDS\\t\" ${ANNOTATIONS}/gencode.v27lift37.basic.annotation.gff3 | grep -vP \"chrM\\t\" > ${ANNOTATIONS}/gencode.v27lift37.cds.gff3\n",
    "# Coding gene list. gene_id always on column 9, 3th field\n",
    "cut -f1,9 gencode.v27lift37.cds.gff3 | tr ';' '\\t' | cut -f1,4 | sort -u | sort -k1,1 > ${ANNOTATIONS}/codingGeneList.txt\n",
    "\n",
    "CHR=( 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y )\n",
    "# Parse gff file by chr\n",
    "for chrNumber in \"${CHR[@]}\"\n",
    "do\n",
    "    echo ${chrNumber}\n",
    "    grep -P \"chr${chrNumber}\\t\"  ${ANNOTATIONS}/gencode.v27lift37.basic.annotation.gff3 | sort -k4,4n > ${BASIC}/gencode.v27lift37.basic.annotation.chr${chrNumber}.gff3 \n",
    "    grep -P \"chr${chrNumber}\\t\"  ${ANNOTATIONS}/gencode.v27lift37.cds.gff3 | sort -k1,1 -k4,4n > ${CDS}/gencode.v27lift37.cds.chr${chrNumber}.gff3 \n",
    "    grep -P \"chr${chrNumber}\\t\"  ${ANNOTATIONS}/gencode.v27lift37.genes.gff3 | sort -k1,1 -k4,4n > ${GENES}/gencode.v27lift37.genes.chr${chrNumber}.gff3 \n",
    "done\n",
    "\n",
    "rm ${ANNOTATIONS}/gencode.v27lift37.basic.annotation.gff3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Basic cleaned gene file\n",
    "This file will include information about chromosomes, start coordinates, end coordinates, strand, gene id and gene name. It will be and perform calculations on gene coordinates. Kind of gff file easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ANNOTATIONS='/home/jmurga/mkt/201903/rawData/humans/annotations'\n",
    "BASIC='/home/jmurga/mkt/201903/rawData/humans/annotations/basicAnnotation'\n",
    "GENES='/home/jmurga/mkt/201903/rawData/humans/annotations/genes'\n",
    "# Cleaned gene file. Including chr, start, end, id and symbol. At gene entries geneid and genesymbol always on field 5 and 7or8\n",
    "touch ${ANNOTATIONS}/gencodeGenesCleaned.tab \n",
    "printf \"chr\\tstart\\tend\\tstrand\\tid\\tname\\n\" > ${ANNOTATIONS}/gencodeGenesCleaned.tab\n",
    "\n",
    "time while read LINE;\n",
    "do \n",
    "    CHR=$(echo ${LINE} | cut -d' ' -f1 ); \n",
    "    GENE=$(echo ${LINE} | cut -d' ' -f2); \n",
    "    fgrep `echo ${GENE}`  ${GENES}/gencode.v27lift37.genes.${CHR}.gff3 | grep -P \"\\tgene\\t\" | cut -f1,4,5,7,9 | tr ';' '\\t' | cut -f1,2,3,4,6,8,9 | awk '{if($6 ~ /gene_name/) print $1,$2,$3,$4,$5,$6;else print $1,$2,$3,$4,$5,$7}' | tr ' ' '\\t' | sed 's/gene_id=//g' | sed 's/gene_name=//g' \n",
    "done < ${ANNOTATIONS}/codingGeneList.txt >> ${ANNOTATIONS}/gencodeGenesCleaned.tab\n",
    "\n",
    "sort -k1,1 -k2,2n ${ANNOTATIONS}/gencodeGenesCleaned.tab > ${ANNOTATIONS}/tmpAnnotation && mv ${ANNOTATIONS}/tmpAnnotation ${ANNOTATIONS}/gencodeGenesCleaned.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0,sep='\\t')\n",
    "dfGenes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputGeneList = dfGenes.loc[:,'id'].apply(lambda x: re.sub(r\"\\..*$\", \"\",x))\n",
    "idCleaned = pd.DataFrame(data = {'id': dfGenes.loc[:,'id'],'idCleaned':inputGeneList})\n",
    "idCleaned.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idCleaned.to_csv(DATA + '/annotations/idCleaned.tab',header=True,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDS human degenerancy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Raw cds coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ANNOTATIONS='/home/jmurga/mkt/201903/rawData/humans/annotations'\n",
    "CDS='/home/jmurga/mkt/201903/rawData/humans/annotations/cds'\n",
    "TEMPORAL='/home/jmurga/mkt/201903/rawData/humans/annotations/tmp'\n",
    "\n",
    "touch ${ANNOTATIONS}/cdsCoordinates.tab\n",
    "printf \"id\\tchr\\ttranscript\\ttranscriptSize\\tcoordinates\\n\" > ${ANNOTATIONS}/cdsCoordinates.tab\n",
    "\n",
    "time tail -n+2 ${ANNOTATIONS}/gencodeGenesCleaned.tab | while read LINE;\n",
    "do \n",
    "    echo '*************'\n",
    "    echo $LINE | cut -d' ' -f5\n",
    "    \n",
    "    CHR=$(echo ${LINE} | cut -d' ' -f1)\n",
    "    GENE=$(echo ${LINE} | cut -d' ' -f5)\n",
    "\n",
    "    fgrep ${GENE} ${CDS}/gencode.v27lift37.cds.${CHR}.gff3  | cut -f9 | tr ';' '\\n' | fgrep transcript_id | sort -u | cut -d'=' -f2 > ${TEMPORAL}/transcriptTmp.tab\n",
    "\n",
    "\n",
    "    while read transcript; do fgrep ${transcript} ${CDS}/gencode.v27lift37.cds.${CHR}.gff3 | awk '{print $4,$5,$5-$4}' | awk -v transcript=\"$transcript\" -v genes=${GENE} -v chr=${CHR}  '{sum+=$3} {printf $1\",\"$2\",\"} END{printf \"\\t\"genes\"\\t\"chr\"\\t\"transcript\"\\t\"sum\"\\n\"}' | awk '{print $2,$3,$4,$5,$1}' | sed 's/,$//' | tr ' ' '\\t' >> ${ANNOTATIONS}/cdsCoordinates.tab ;done < ${TEMPORAL}/transcriptTmp.tab\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check degenerancy by position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking degenerancy by positions taking into account all transcripts and genes independently**  \n",
    "Recoding CDS sequences to get 0fold, 2fold, 3fold and 4fold positions by transcript and genes, in order to estimate frequencies and divergence by type of functional sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T18:11:07.770004Z",
     "start_time": "2019-02-20T18:11:07.765366Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, SRC)\n",
    "from reverseComplement import reverseComplement\n",
    "from degenerancy import degenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T15:55:58.866073Z",
     "start_time": "2019-02-26T15:55:58.431785Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0 ,usecols=['id','chr','strand'],sep='\\t')\n",
    "cds = pd.read_csv(DATA + '/annotations/cdsCoordinates.tab',header=0,sep='\\t')\n",
    "cds = pd.merge(cds, dfGenes[['id','strand','chr']],  how='right', left_on=['chr','id'], right_on = ['chr','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T18:19:12.643870Z",
     "start_time": "2019-02-20T18:19:12.615592Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Rewrite file each execution\n",
    "degen = []\n",
    "allPositions = []\n",
    "nchr = []\n",
    "\n",
    "import time\n",
    "for index, row in cds.iterrows():\n",
    "    start_time = time.time()\n",
    "    print(index,row['id'])\n",
    "    chrFile = px.Fasta('/home/jmurga/mkt/201903/rawData/humans/fastas/ref/' + row['chr'] +'.fa',sequence_always_upper=True)\n",
    "    # Convert CDS list into numeric array\n",
    "    coordinates = np.array(row['coordinates'].split(',')).astype(int).tolist()\n",
    "    coordinates =  [coordinates[i:i+2] for i in range(0, len(coordinates), 2)]\n",
    "    # Extract all CDS positions in a list in order to merge with degenerate sequences (same length -> same index)\n",
    "    positions=[]\n",
    "    for i in range(0,len(coordinates),1):\n",
    "        positions.append(list(range(coordinates[i][0],coordinates[i][1]+1)))  \n",
    "    positions = [item for sublist in positions for item in sublist]\n",
    "    # Extract cds sequences\n",
    "    seq = chrFile.get_spliced_seq(row['chr'], coordinates).seq\n",
    "\n",
    "    if(row['strand'] == '-'):\n",
    "        seq = reverseComplement(seq)\n",
    "        allPositions = allPositions[::-1]\n",
    "    if((len(seq)/3).is_integer() and seq[0:3]=='ATG'):\n",
    "        m = degenerate(seq)\n",
    "        degen.append(list(m))\n",
    "        allPositions.append(positions)\n",
    "        nchr.append([row['chr']] * len(m))\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "#         degenerateDF = pd.DataFrame({'chr':j,'m':list(m),'POS':allPositions})\n",
    "#         degeneratePositions = pd.concat([degeneratePositions,degenerateDF])\n",
    "nchr = [item for sublist in nchr for item in sublist]\n",
    "degen = [item for sublist in degen for item in sublist]\n",
    "allPositions = [item for sublist in allPositions for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'CHR':nchr,'POS':allPositions,'degen':degen}) \n",
    "for i in df['CHR'].unique():\n",
    "    tmp = df[df['CHR'] == i]\n",
    "    tmp = tmp.groupby(['CHR','POS'])['degen'].apply(lambda x: ','.join(x)).reset_index()\n",
    "    tmp.to_csv('/home/jmurga/mkt/201903/rawData/humans/annotations/degeneracyHumanPositions.tab',mode='a',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning positions degenerancy based on most constrain posibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T09:23:40.180883Z",
     "start_time": "2019-02-25T09:23:21.067990Z"
    }
   },
   "outputs": [],
   "source": [
    "degenerancyPositions = pd.read_csv(DATA + '/annotations/degeneracyHumanPositions.tab',sep='\\t',header=0)\n",
    "degenerancyPositions['type'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def foldPositions(x):\n",
    "    if('0' in x):\n",
    "        return('0fold')\n",
    "    elif('4' in x and '0' not in x and '2' not in x and '3' not in x):\n",
    "        return('4fold')\n",
    "    elif('2' in x and '0' not in x and '4' not in x and '3' not in x):\n",
    "        return('2fold')\n",
    "    elif('2' not in x and '0' not in x and '4' not in x) :\n",
    "        return('3fold')\n",
    "    else:\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degenerancyPositions['type'] = degenerancyPositions['m'].apply(foldPositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = degenerancyPositions[(degenerancyPositions['type']=='0fold') | (degenerancyPositions['type']=='4fold')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA + '/annotations/zeroFourFoldPositions.tab',header=True,index=False,sep='\\t')\n",
    "df.to_hdf(DATA + '/annotations/zeroFourFoldPositions.h5','degenerancy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Creating Derived Allele Frequency and Divergence file by populations and type of site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T09:29:16.820939Z",
     "start_time": "2019-02-20T09:29:16.809010Z"
    },
    "heading_collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "source": [
    "#### Extracting mi and m0 position by largest transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0 ,sep='\\t')\n",
    "cds = pd.read_csv(DATA + '/cdsCoordinates.tab',header = 0 ,sep='\\t')\n",
    "cds = cds.loc[cds.reset_index().groupby(['chr','id'])['transcriptSize'].idxmax()].reset_index(drop=True)\n",
    "cds = pd.merge(dfGenes,cds,on=['chr','id'])\n",
    "degeneratePositions = pd.read_hdf(DATA + '/annotations/zeroFourFoldPositions.h5','positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for j in cds['chr'].unique():\n",
    "    print(j)\n",
    "    chrPositions = degeneratePositions[degeneratePositions['CHROM']==j]\n",
    "#     for index, row in cds[cds['chr']==j].iterrows():\n",
    "    for index, row in cds[cds['id']=='ENSG00000079102.16_3'].iterrows():\n",
    "        print(index,row['id'])\n",
    "        chrFile = Fasta(DATA + '/refFastas/' + row['chr'] +'.fa')\n",
    "    #     Convert CDS list into numeric array\n",
    "        coordinates = array(row['coordinates'].split(',')).astype(int).tolist()\n",
    "        coordinates =  [coordinates[i:i+2] for i in range(0, len(coordinates), 2)]\n",
    "        # Extract all CDS positions in a list in order to merge with degenerate sequences (same length -> same index)\n",
    "        positions=[]\n",
    "        for i in range(0,len(coordinates),1):\n",
    "            positions.append(list(range(coordinates[i][0],coordinates[i][1]+1)))  \n",
    "        allPositions = [item for sublist in positions for item in sublist]\n",
    "        # Extract cds sequences\n",
    "        seq = chrFile.get_spliced_seq(row['chr'].replace('chr',''), coordinates).seq.upper()\n",
    "    #     print(len(seq))\n",
    "        if(row['strand'] == '-'):\n",
    "            seq = reverseComplement(seq)\n",
    "            allPositions = allPositions[::-1]\n",
    "        if((len(seq)/3).is_integer() and seq[0:3]=='ATG'):\n",
    "            m = degenerate(seq)\n",
    "            tmp = pd.DataFrame({'POS':allPositions,'m':list(m)})\n",
    "            tmp['CHROM']=row['chr']\n",
    "            tmp = pd.merge(chrPositions[['CHROM','POS','type']],tmp,on=['CHROM','POS'],how='right')\n",
    "            counts = tmp['type'].value_counts()\n",
    "            \n",
    "            if(counts.shape[0]<2 or '4fold' not in counts.index):\n",
    "                m0=0\n",
    "                mi=counts['0fold']\n",
    "            else:\n",
    "                m0=counts['4fold']\n",
    "                mi=counts['0fold']\n",
    "            data = pd.DataFrame({'id':row['id'],'mi':mi,'m0':m0},index=[0])\n",
    "            data.to_csv(DATA+'/annotations/refAnalizableSytes.tab',sep='\\t',header=False,index=False,mode='a')\n",
    "        else:\n",
    "            data = pd.DataFrame({'id':row['id'],'mi':0,'m0':0},index=[0])\n",
    "            data.to_csv(DATA+'/annotations/tmp/refAnalizableSytes.tab',sep='\\t',header=False,index=False,mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:01:55.467605Z",
     "start_time": "2019-02-28T18:01:53.659003Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pops = ['ACB','ASW','BEB','CDX','CEU','CHB','CHS','CLM','ESN','FIN','GBR','GIH','GWD','IBS','ITU','JPT','KHV','LWK','MSL','MXL','PEL','PJL','PUR','STU','TSI','YRI']\n",
    "refAnalizableSites = pd.read_csv(DATA+'/annotations/refAnalyzableSites.tab',sep='\\t',header=None,names=['id','mi','m0'])\n",
    "\n",
    "totalFoldPositionsByPop = pd.DataFrame()\n",
    "for p in pops:\n",
    "    print(p)\n",
    "    refAnalizableSites['pop'] = p\n",
    "    \n",
    "    totalFoldPositionsByPop = totalFoldPositionsByPop.append(refAnalizableSites)\n",
    "\n",
    "totalFoldPositionsByPop = totalFoldPositionsByPop.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Polymorphism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "##### Manual recode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Extract coordinates from largest transcript to estimate allele frequency from variant data and merge with precalculated types of sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:31:06.565806Z",
     "start_time": "2019-03-01T17:30:54.493100Z"
    },
    "hidden": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0 ,sep='\\t')\n",
    "cds = pd.read_csv(DATA + '/cdsCoordinates.tab',header = 0 ,sep='\\t')\n",
    "cds = cds.loc[cds.reset_index().groupby(['chr','id'])['transcriptSize'].idxmax()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:31:06.769554Z",
     "start_time": "2019-03-01T17:31:06.704847Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Extracting largest transcript coordinates to check variants at these specific positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T10:05:24.979040Z",
     "start_time": "2019-02-27T10:05:21.843771Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# columns = ['POS','id','transcript']\n",
    "# for index,row in cds.iterrows():\n",
    "#     print(index,row['id'])\n",
    "#     coordinates = array(row['coordinates'].split(',')).astype(int).tolist()\n",
    "#     coordinates =  [coordinates[i:i+2] for i in range(0, len(coordinates), 2)]\n",
    "    \n",
    "#     # Extract all CDS positions in a list in order to merge with degenerate sequences (same length -> same index)\n",
    "#     positions=[]\n",
    "    \n",
    "#     for i in range(0,len(coordinates),1):\n",
    "#         positions.append(list(range(coordinates[i][0],coordinates[i][1]+1)))  \n",
    "#     allPositions = [item for sublist in positions for item in sublist]\n",
    "    \n",
    "# #     tmp = pd.DataFrame({'POS':allPositions,'id':row['id'],'transcript':row['transcript']})\n",
    "#     tmp = pd.DataFrame({'CHROM':row['chr'],'POS':allPositions,'id':row['id'],'transcript':row['transcript']})\n",
    "#     tmp.to_csv(DATA+'/annotations/largestTranscriptCoordinates.tab',mode='a',index=False,sep='\\t')\n",
    "#     tmp.to_hdf(DATA+'/annotations/largestTranscriptCoordinates.h5','positions',append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T09:50:04.390944Z",
     "start_time": "2019-03-06T09:50:03.132598Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!python /home/jmurga/mkt/201903/scripts/src/sfsFromVcf.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!python /home/jmurga/mkt/201903/scripts/src/sfsFromVcf.py --data gencodeGenesCleaned.tab --cds largestTranscriptCoordinates.h5 --vcf 1000GP --chromosomes all --populations Phase3\n",
    "\n",
    "!python /home/jmurga/mkt/201903/scripts/src/sfsFromVcf.py --data gencodeGenesCleaned.tab --cds cdsCoordinates.tab --vcf 1000GP --chromosomes all --populations Phase3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Subtract low quality positions from variants using bedtools intersect and 1000GP pilot mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "intersectBed -a <(awk '{print $1\"\\t\"$2-1\"\\t\"$2\"\\t\"$3\"\\t\"$4\"\\t\"$5\"\\t\"$6\"\\t\"$7\"\\t\"$8\"\\t\"$9\"\\t\"$10}' manualRawFrequencies.tab) -b <(sed 's/chr//g' /data/shared/1000GP/Masks/20141020.pilot_mask.whole_genome.bed) | cut -f1,3,4,5,6,7,8,9,10 > manualRawFrequenciesMasked.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rawFrequencies = pd.read(DATA + '/alleleFrequencies/manualRawFrequenciesMasked.tab',header=None,sep='\\t')\n",
    "rawFrequencies.columns = ['CHROM','POS','AC','AN','REF','ALT','AA','pop','id','transcript']\n",
    "rawFrequencies.to_hdf(DATA + '/alleleFrequencies/manualRawFrequenciesMasked.h5','variants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T09:23:13.851610Z",
     "start_time": "2019-02-27T09:23:13.847147Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### SFS, Pi and P0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:03:09.272253Z",
     "start_time": "2019-02-28T17:02:52.703572Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%time pol = pd.read_hdf('/home/jmurga/mkt/201903/rawData/humans/alleleFrequencies/manualRawFrequenciesMasked.h5') \n",
    "pol = pol[(pol['AC']!=0) & (pol['AC']!=pol['AN'])]\n",
    "pol = pol[(pol['AA']!='.') & (pol['AA']!='N') & (pol['AA']!='-')].dropna()\n",
    "# pol = pol[(pol['CHROM']==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:06:45.084008Z",
     "start_time": "2019-02-28T17:03:09.339849Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time pol['derivedAlleleFrequency'] = pol.apply(lambda x: x['AC']/x['AN'] if x['AA']==x['REF'] else (x['AN']-x['AC'])/x['AN'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:06:45.192002Z",
     "start_time": "2019-02-28T17:06:45.142946Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:31:36.007773Z",
     "start_time": "2019-02-26T09:31:36.003592Z"
    },
    "hidden": true
   },
   "source": [
    "Checking positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:08:45.278645Z",
     "start_time": "2019-02-28T17:07:44.899770Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# positions = pd.read_csv(DATA + '/annotations/zeroFourFoldPositions.tab',header=0,sep='\\t')\n",
    "%time positions = pd.read_hdf(DATA + '/annotations/zeroFourFoldPositions.h5','positions')\n",
    "positions.columns = ['CHROM','POS','m','type']\n",
    "positions['CHROM'] = positions['CHROM'].apply(lambda x: re.sub('chr','',x))\n",
    "\n",
    "positions['CHROM']=positions['CHROM'].astype(str)\n",
    "positions['POS']=positions['POS'].astype(int)\n",
    "\n",
    "pol['CHROM']=pol['CHROM'].astype(str)\n",
    "pol['POS']=pol['POS'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:09:12.321784Z",
     "start_time": "2019-02-28T17:08:45.367389Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pol = pd.merge(pol,positions,on=['CHROM','POS'],how='inner')\n",
    "pol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Binning by daf categories and creating new column from *type* to count number of occurrence by each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:09:12.525324Z",
     "start_time": "2019-02-28T17:09:12.325668Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = np.arange(0,1.05,0.05)\n",
    "labels = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1]\n",
    "# daf['categories'] = pd.cut(daf['freq'],bins=bins,labels=labels).astype(float).fillna(0)\n",
    "pol['categories'] = pd.cut(pol['derivedAlleleFrequency'],bins=bins,labels=labels)\n",
    "# Creating new column from type to count number of occurrence by category\n",
    "pol['count'] = pol['type']\n",
    "pol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Counting total of sites grouping 0fold and 4fold categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:09:17.681592Z",
     "start_time": "2019-02-28T17:09:12.527827Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "totalSites = pol.groupby(['id','CHROM','pop','type'])['categories'].count().reset_index()\n",
    "totalSites = totalSites.pivot_table(index=['id','CHROM','pop'], columns=['type'],values='categories').reset_index()\n",
    "totalSites.columns = ['id','chr','pop','pi','p0']\n",
    "totalSites = totalSites.fillna(0)\n",
    "totalSites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Parsing Sites Frequency Spectrum to create a dataframe compatible with *iMKT R package*. Next steps include execute MKT over genes and populations using a modification of this packages. It was programmed to parse the SFS as string with dotComma separated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:18:48.858632Z",
     "start_time": "2019-02-28T17:09:17.684102Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sfs = pol.loc[:,['id','pop','type','categories','count']].groupby(['id','pop','type','categories']).count().reset_index()\n",
    "sfs.columns = ['id','pop','type','categories','count']\n",
    "sfs['count'] = sfs['count'].fillna(0).astype(int)\n",
    "sfs = sfs.groupby(['id','pop','type'])['count'].apply(list).reset_index()\n",
    "sfs['count'] = sfs['count'].apply(lambda x:';'.join(map(str,x)))\n",
    "sfs = sfs.pivot_table(index=['id','pop'], columns=['type'],values='count',aggfunc=lambda x: ' '.join(x)).reset_index()\n",
    "sfs.columns = ['id','pop','daf0f','daf4f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:18:48.876009Z",
     "start_time": "2019-02-28T17:18:48.861783Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:18:50.069607Z",
     "start_time": "2019-02-28T17:18:48.878235Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "daf = pd.merge(totalSites,sfs,on=['id','pop'])\n",
    "daf = daf.fillna(0)\n",
    "print(daf.shape)\n",
    "daf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:18:50.126983Z",
     "start_time": "2019-02-28T17:18:50.072616Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daf[daf['id']=='ENSG00000115850.9_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T15:31:08.598Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Extracting div sites from chimp alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T09:49:52.442647Z",
     "start_time": "2019-03-06T09:49:51.181312Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!python /home/jmurga/mkt/201903/scripts/src/alleleFrequencyByPop.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!python /home/jmurga/mkt/201903/scripts/src/alleleFrequencyByPop.py --data gencodeGenesCleaned.tab --cds largestTranscriptCoordinates.h5 --VCF Alns --chromosomes all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Subtract low quality positions from variants using bedtools intersect and 1000GP pilot mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "intersectBed -a <(awk '{print $1\"\\t\"$2-1\"\\t\"$2\"\\t\"$3\"\\t\"$4\"\\t\"$5\"\\t\"$6\"\\t\"$7\"}' manualRawFrequencies.tab) -b <(sed 's/chr//g' /data/shared/1000GP/Masks/20141020.pilot_mask.whole_genome.bed) | cut -f1,3,4,5,6,7 > manualRawFrequenciesMasked.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "divPositions = pd.read(DATA + '/alleleFrequencies/manualRawFrequenciesMasked.tab',header=None,sep='\\t')\n",
    "divPositions.columns = ['CHROM','POS','REF','ALT','GT','id','transcript']\n",
    "divPositions.to_hdf(DATA + '/alleleFrequencies/manualRawFrequenciesMasked.h5','variants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Calculating div sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:49:17.918526Z",
     "start_time": "2019-02-28T17:48:16.299176Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fixedPol = pd.read_hdf('/home/jmurga/mkt/201903/rawData/humans/alleleFrequencies/manualRawFrequenciesMasked.h5','variants')\n",
    "fixedPol['AA'] = fixedPol['AA'].str.upper()\n",
    "fixedPol = fixedPol[(fixedPol['AA']!='.') & (fixedPol['AA']!='N') & (fixedPol['AA']!='-')].dropna()\n",
    "fixedPol = fixedPol[(fixedPol['AC']==0) | (fixedPol['AC']==fixedPol['AN'])]\n",
    "fixedPol['CHROM'] = fixedPol['CHROM'].astype(str)\n",
    "fixedPol['POS'] = fixedPol['POS'].astype(int)\n",
    "fixedPol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:49:18.516329Z",
     "start_time": "2019-02-28T17:49:18.281288Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "div = pd.read_hdf('/home/jmurga/mkt/201903/rawData/humans/alleleFrequencies/manualDivergenceVariantsMasked.h5')\n",
    "div = div[(div['ALT']!='N') & (div['ALT']!='')]\n",
    "div['CHROM'] = div['CHROM'].astype(str)\n",
    "div['POS'] = div['POS'].astype(int)\n",
    "div.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:50:26.807074Z",
     "start_time": "2019-02-28T17:49:18.870166Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "positions = pd.read_hdf(DATA + '/annotations/zeroFourFoldPositions.h5','positions')\n",
    "positions.columns = ['CHROM','POS','m','type']\n",
    "positions['CHROM'] = positions['CHROM'].astype(str)\n",
    "positions['POS'] = positions['POS'].astype(int)\n",
    "positions['CHROM'] = positions['CHROM'].apply(lambda x: re.sub('chr','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:50:52.064703Z",
     "start_time": "2019-02-28T17:50:27.167004Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "div = pd.merge(div,positions,on=['CHROM','POS'],how='inner')\n",
    "div.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Iterate each pop and merge with divergent variants extract with VEP. Each iteration subset population and get only fixed variants in each population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:52:07.238976Z",
     "start_time": "2019-02-28T17:50:52.431404Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subset all populations in dataframe\n",
    "pops = fixedPol['pop'].unique()\n",
    "\n",
    "# Empty df to append each population\n",
    "divSites = pd.DataFrame()\n",
    "\n",
    "for p in pops:\n",
    "    print(p)\n",
    "    # Subset population and fixed variants\n",
    "    fixedPolSubset = fixedPol[fixedPol['pop'] == p]\n",
    "\n",
    "    # Merging all fixed variants and posible divergent sites\n",
    "    divPol = pd.merge(div[['POS','CHROM','GT','id','type']],fixedPolSubset[['POS','CHROM','AC']],on=['CHROM','POS'],how='outer')\n",
    "    \n",
    "    # Extract and count real divergent sites     \n",
    "    divPol.loc[:,'d'] = np.nan\n",
    "    divPol.loc[:,'d'] = divPol[~divPol['GT'].isna()]['d'].fillna(1)\n",
    "    divPol = divPol[~divPol['d'].isna()]\n",
    "    \n",
    "    # Cleaning and grouping divergent site by id\n",
    "    tmp = divPol[['POS','id','type','d']]\n",
    "    tmp = tmp.groupby(['id','type'])['d'].count().reset_index()\n",
    "    tmp = tmp.pivot_table(index=['id'],columns=['type'],values='d').reset_index()\n",
    "    tmp.columns = ['id','di','d0']\n",
    "    tmp = tmp.fillna(0)\n",
    "    tmp['pop'] = p\n",
    "\n",
    "    # Append results to df by pop\n",
    "    divSites = divSites.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:52:07.755869Z",
     "start_time": "2019-02-28T17:52:07.621250Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "divSites[divSites['id']=='ENSG00000115850.9_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T16:45:32.477702Z",
     "start_time": "2019-02-05T16:45:32.453534Z"
    },
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Merging Derived Allele Frequencies, divergency and total analyzed sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0 ,usecols=['id','chr'],sep='\\t') \n",
    "dfGenes['chr']=dfGenes['chr'].apply(lambda x: re.sub('chr','',x))\n",
    "pops = ['ACB','ASW','BEB','CDX','CEU','CHB','CHS','CLM','ESN','FIN','GBR','GIH','GWD','IBS','ITU','JPT','KHV','LWK','MSL','MXL','PEL','PJL','PUR','STU','TSI','YRI']\n",
    "\n",
    "ids = pd.DataFrame()\n",
    "for p in pops:\n",
    "    print(p)\n",
    "    dfGenes['pop'] = p\n",
    "    \n",
    "    ids = ids.append(dfGenes)\n",
    "\n",
    "ids = ids.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:14.076794Z",
     "start_time": "2019-02-28T18:02:13.209761Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfToMerge = pd.merge(daf,totalFoldPositionsByPop,on=['id','pop'],how='outer')\n",
    "dfToMerge['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfToMerge = pd.merge(dfToMerge,ids,on=['chr','id','pop'],how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:18.373006Z",
     "start_time": "2019-02-28T18:02:15.433627Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "humanGenes = pd.merge(dfToMerge, divSites,on=['id','pop'],how='outer')\n",
    "humanGenes = humanGenes.sort_values(['chr','id','pop'])\n",
    "humanGenes[humanGenes['daf0f'].isna()].loc[:,'daf0f'] = '0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0'\n",
    "humanGenes[humanGenes['daf4f'].isna()].loc[:,'daf4f'] = '0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0'\n",
    "humanGenes['daf0f'] = humanGenes['daf0f'].fillna('0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0')\n",
    "humanGenes['daf4f'] = humanGenes['daf4f'].fillna('0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0')\n",
    "humanGenes = humanGenes.fillna(0)\n",
    "humanGenes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:19.856686Z",
     "start_time": "2019-02-28T18:02:19.431496Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0 ,usecols=['id','name'],sep='\\t')\n",
    "humanGenes = pd.merge(humanGenes,dfGenes,on=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:21.912601Z",
     "start_time": "2019-02-28T18:02:21.880922Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "humanGenes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:24.170869Z",
     "start_time": "2019-02-28T18:02:23.758348Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfRecomb = pd.read_csv(DATA + '/genesRecomb.tab',header = 0 ,sep='\\t')\n",
    "humanGenes = pd.merge(humanGenes,dfRecomb,on=['id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:26.400297Z",
     "start_time": "2019-02-28T18:02:26.356547Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "humanGenes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:36.353963Z",
     "start_time": "2019-02-28T18:02:28.531173Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "humanGenes.to_csv('/home/jmurga/mkt/201903/rawData/humans/humanGenesPhase3Masked.tab',sep='\\t',index=False,header=True,na_rep=\"NA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
