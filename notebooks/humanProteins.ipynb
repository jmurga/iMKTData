{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:07:34.203001Z",
     "start_time": "2019-02-28T17:07:34.199035Z"
    }
   },
   "outputs": [],
   "source": [
    "SRC='/home/jmurga/mkt/201903/scripts/src'\n",
    "DATA='/home/jmurga/mkt/201903/rawData/humans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:07:32.555395Z",
     "start_time": "2019-02-28T17:07:32.501542Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import allel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyfaidx as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, SRC)\n",
    "from reverseComplement import reverseComplement\n",
    "from degenerancy import degenerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Human genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T09:55:47.492822Z",
     "start_time": "2019-03-06T09:55:47.484081Z"
    },
    "hidden": true
   },
   "source": [
    "To execute bash code we created a snippets through nbextensions containing the following paths in order to avoid copy and paste cells. %%bash magic do not recognize previous variables. Adding mkdir command to create necesary paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "DATA='/home/jmurga/mkt/201903/rawData/humans/annotations'\n",
    "BASIC='/home/jmurga/mkt/201903/rawData/humans/annotations/basicAnnotation'\n",
    "CDS='/home/jmurga/mkt/201903/rawData/humans/annotations/cds'\n",
    "GENES='/home/jmurga/mkt/201903/rawData/humans/annotations/genes'\n",
    "TEMPORAL='/home/jmurga/mkt/201903/rawData/humans/annotations/tmp'\n",
    "ALLELEFREQ='/home/jmurga/mkt/201903/rawData/humans/alleleFrequencies'\n",
    "\n",
    "mkdir -p ${DATA}\n",
    "mkdir -p ${BASIC}\n",
    "mkdir -p ${CDS}\n",
    "mkdir -p ${GENES}\n",
    "mkdir -p ${TEMPORAL}\n",
    "mkdir -p ${ALLELEFREQ}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Download [gencode annotation](https://www.gencodegenes.org/human/release_27lift37.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T09:58:30.923202Z",
     "start_time": "2019-03-06T09:58:17.481212Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "DATA='/home/jmurga/mkt/201903/rawData/humans'\n",
    "ANNOTATIONS='/home/jmurga/mkt/201903/rawData/humans/annotations'\n",
    "EXPRESSION='/home/jmurga/mkt/201903/rawData/humans/expression'\n",
    "\n",
    "cd ${ANNOTATIONS}\n",
    "# Gencode annotation\n",
    "wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_27/GRCh37_mapping/gencode.v27lift37.basic.annotation.gff3.gz\n",
    "gunzip *.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Download reference fastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "DATA='/home/jmurga/mkt/201903/rawData/humans'\n",
    "FASTAS='/home/jmurga/mkt/201903/rawData/humans/fastas/'\n",
    "mkdir - p ${FASTAS}\n",
    "mkdir - p ${FASTAS}/ref\n",
    "\n",
    "cd ${FASTAS}/ref\n",
    "\n",
    "wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.gz \n",
    "wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/technical/reference/human_g1k_v37.fasta.fai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = px.Fasta('/home/jmurga/mkt/201903/rawData/humans/fastas/ref/human_g1k_v37.fasta',duplicate_action='first',sequence_always_upper=True,read_long_names=True)\n",
    "\n",
    "samples = list(file.keys())[0:24]\n",
    "\n",
    "for nchr in range(0,len(samples),1):\n",
    "    print('>chr' + samples[nchr].split(' ')[0])\n",
    "    f = open('/home/jmurga/mkt/201903/rawData/humans/fastas/ref/chr' + samples[nchr].split(' ')[0] + '.fa' , 'w')\n",
    "    tmp = file[samples[nchr]][:].seq\n",
    "    f.write('>chr' + samples[nchr].split(' ')[0] + '\\n' + file[samples[nchr]][:].seq)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "rm ${FASTA}/ref/human_g1k*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Parsing and cleaning gencode annotation to execute all operations by chr\n",
    "Operate by chr is faster due to grep on smaller files. Each folder contain an specific file foreach chromosome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T10:00:35.284667Z",
     "start_time": "2019-03-06T09:59:09.831022Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ANNOTATIONS='/home/jmurga/mkt/201903/rawData/humans/annotations'\n",
    "BASIC='/home/jmurga/mkt/201903/rawData/humans/annotations/basicAnnotation'\n",
    "CDS='/home/jmurga/mkt/201903/rawData/humans/annotations/cds'\n",
    "GENES='/home/jmurga/mkt/201903/rawData/humans/annotations/genes'\n",
    "\n",
    "mkdir -p ${BASIC}\n",
    "mkdir -p ${CDS}\n",
    "mkdir -p ${GENES}\n",
    "\n",
    "# Deleting commented lines\n",
    "sed -i '/^#/ d' ${ANNOTATIONS}/gencode.v27lift37.basic.annotation.gff3\n",
    "# Extract genes information\n",
    "grep -P \"\\tgene\\t\" ${ANNOTATIONS}/gencode.v27lift37.basic.annotation.gff3 | grep -vP \"chrM\\t\" > ${ANNOTATIONS}/gencode.v27lift37.genes.gff3\n",
    "# Extract CDS information. Only protein coding genes\n",
    "grep -P \"\\tCDS\\t\" ${ANNOTATIONS}/gencode.v27lift37.basic.annotation.gff3 | grep -vP \"chrM\\t\" > ${ANNOTATIONS}/gencode.v27lift37.cds.gff3\n",
    "# Coding gene list. gene_id always on column 9, 3th field\n",
    "cut -f1,9 gencode.v27lift37.cds.gff3 | tr ';' '\\t' | cut -f1,4 | sort -u | sort -k1,1 > ${ANNOTATIONS}/codingGeneList.txt\n",
    "\n",
    "CHR=( 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 X Y )\n",
    "# Parse gff file by chr\n",
    "for chrNumber in \"${CHR[@]}\"\n",
    "do\n",
    "    echo ${chrNumber}\n",
    "    grep -P \"chr${chrNumber}\\t\"  ${ANNOTATIONS}/gencode.v27lift37.basic.annotation.gff3 | sort -k4,4n > ${BASIC}/gencode.v27lift37.basic.annotation.chr${chrNumber}.gff3 \n",
    "    grep -P \"chr${chrNumber}\\t\"  ${ANNOTATIONS}/gencode.v27lift37.cds.gff3 | sort -k1,1 -k4,4n > ${CDS}/gencode.v27lift37.cds.chr${chrNumber}.gff3 \n",
    "    grep -P \"chr${chrNumber}\\t\"  ${ANNOTATIONS}/gencode.v27lift37.genes.gff3 | sort -k1,1 -k4,4n > ${GENES}/gencode.v27lift37.genes.chr${chrNumber}.gff3 \n",
    "done\n",
    "\n",
    "rm ${ANNOTATIONS}/gencode.v27lift37.basic.annotation.gff3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Basic cleaned gene file\n",
    "This file will include information about chromosomes, start coordinates, end coordinates, strand, gene id and gene name. It will be and perform calculations on gene coordinates. Kind of gff file easier to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "ANNOTATIONS='/home/jmurga/mkt/201903/rawData/humans/annotations'\n",
    "BASIC='/home/jmurga/mkt/201903/rawData/humans/annotations/basicAnnotation'\n",
    "GENES='/home/jmurga/mkt/201903/rawData/humans/annotations/genes'\n",
    "# Cleaned gene file. Including chr, start, end, id and symbol. At gene entries geneid and genesymbol always on field 5 and 7or8\n",
    "touch ${ANNOTATIONS}/gencodeGenesCleaned.tab \n",
    "printf \"chr\\tstart\\tend\\tstrand\\tid\\tname\\n\" > ${ANNOTATIONS}/gencodeGenesCleaned.tab\n",
    "\n",
    "time while read LINE;\n",
    "do \n",
    "    CHR=$(echo ${LINE} | cut -d' ' -f1 ); \n",
    "    GENE=$(echo ${LINE} | cut -d' ' -f2); \n",
    "    fgrep `echo ${GENE}`  ${GENES}/gencode.v27lift37.genes.${CHR}.gff3 | grep -P \"\\tgene\\t\" | cut -f1,4,5,7,9 | tr ';' '\\t' | cut -f1,2,3,4,6,8,9 | awk '{if($6 ~ /gene_name/) print $1,$2,$3,$4,$5,$6;else print $1,$2,$3,$4,$5,$7}' | tr ' ' '\\t' | sed 's/gene_id=//g' | sed 's/gene_name=//g' \n",
    "done < ${ANNOTATIONS}/codingGeneList.txt >> ${ANNOTATIONS}/gencodeGenesCleaned.tab\n",
    "\n",
    "sort -k1,1 -k2,2n ${ANNOTATIONS}/gencodeGenesCleaned.tab > ${ANNOTATIONS}/tmpAnnotation && mv ${ANNOTATIONS}/tmpAnnotation ${ANNOTATIONS}/gencodeGenesCleaned.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0,sep='\\t')\n",
    "dfGenes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "inputGeneList = dfGenes.loc[:,'id'].apply(lambda x: re.sub(r\"\\..*$\", \"\",x))\n",
    "idCleaned = pd.DataFrame(data = {'id': dfGenes.loc[:,'id'],'idCleaned':inputGeneList})\n",
    "idCleaned.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idCleaned.to_csv(DATA + '/annotations/idCleaned.tab',header=True,index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDS human degenerancy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw cds coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ANNOTATIONS='/home/jmurga/mkt/201903/rawData/humans/annotations'\n",
    "CDS='/home/jmurga/mkt/201903/rawData/humans/annotations/cds'\n",
    "TEMPORAL='/home/jmurga/mkt/201903/rawData/humans/annotations/tmp'\n",
    "\n",
    "touch ${ANNOTATIONS}/cdsCoordinates.tab\n",
    "printf \"id\\tchr\\ttranscript\\ttranscriptSize\\tcoordinates\\n\" > ${ANNOTATIONS}/cdsCoordinates.tab\n",
    "\n",
    "time tail -n+2 ${ANNOTATIONS}/gencodeGenesCleaned.tab | while read LINE;\n",
    "do \n",
    "    echo '*************'\n",
    "    echo $LINE | cut -d' ' -f5\n",
    "    \n",
    "    CHR=$(echo ${LINE} | cut -d' ' -f1)\n",
    "    GENE=$(echo ${LINE} | cut -d' ' -f5)\n",
    "\n",
    "    fgrep ${GENE} ${CDS}/gencode.v27lift37.cds.${CHR}.gff3  | cut -f9 | tr ';' '\\n' | fgrep transcript_id | sort -u | cut -d'=' -f2 > ${TEMPORAL}/transcriptTmp.tab\n",
    "\n",
    "\n",
    "    while read transcript; do fgrep ${transcript} ${CDS}/gencode.v27lift37.cds.${CHR}.gff3 | awk '{print $4,$5,$5-$4}' | awk -v transcript=\"$transcript\" -v genes=${GENE} -v chr=${CHR}  '{sum+=$3} {printf $1\",\"$2\",\"} END{printf \"\\t\"genes\"\\t\"chr\"\\t\"transcript\"\\t\"sum\"\\n\"}' | awk '{print $2,$3,$4,$5,$1}' | sed 's/,$//' | tr ' ' '\\t' >> ${ANNOTATIONS}/cdsCoordinates.tab ;done < ${TEMPORAL}/transcriptTmp.tab\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check degenerancy by position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking degenerancy by positions taking into account all transcripts and genes independently**  \n",
    "Recoding CDS sequences to get 0fold, 2fold, 3fold and 4fold positions by transcript and genes, in order to estimate frequencies and divergence by type of functional sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T18:11:07.770004Z",
     "start_time": "2019-02-20T18:11:07.765366Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, SRC)\n",
    "from reverseComplement import reverseComplement\n",
    "from degenerancy import degenerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T15:55:58.866073Z",
     "start_time": "2019-02-26T15:55:58.431785Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0 ,usecols=['id','chr','strand'],sep='\\t')\n",
    "cds = pd.read_csv(DATA + '/annotations/cdsCoordinates.tab',header=0,sep='\\t')\n",
    "cds = pd.merge(cds, dfGenes[['id','strand','chr']],  how='right', left_on=['chr','id'], right_on = ['chr','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T18:19:12.643870Z",
     "start_time": "2019-02-20T18:19:12.615592Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for index, row in cds.iterrows():\n",
    "    # Rewrite file each execution\n",
    "    degen = []\n",
    "    allPositions = []\n",
    "    nchr = []\n",
    "    start_time = time.time()\n",
    "    print(index,row['id'])\n",
    "    chrFile = px.Fasta('/home/jmurga/mkt/201903/rawData/humans/fastas/ref/' + row['chr'] +'.fa',sequence_always_upper=True)\n",
    "    # Convert CDS list into numeric array\n",
    "    coordinates = np.array(row['coordinates'].split(',')).astype(int).tolist()\n",
    "    coordinates =  [coordinates[i:i+2] for i in range(0, len(coordinates), 2)]\n",
    "    # Extract all CDS positions in a list in order to merge with degenerate sequences (same length -> same index)\n",
    "    positions=[]\n",
    "    for i in range(0,len(coordinates),1):\n",
    "        positions.append(list(range(coordinates[i][0],coordinates[i][1]+1)))  \n",
    "    positions = [item for sublist in positions for item in sublist]\n",
    "    # Extract cds sequences\n",
    "    seq = chrFile.get_spliced_seq(row['chr'], coordinates).seq\n",
    "    if(row['strand'] == '-'):\n",
    "        seq = reverseComplement(seq)\n",
    "        allPositions = allPositions[::-1]\n",
    "    if((len(seq)/3).is_integer() and seq[0:3]=='ATG'):\n",
    "        m = degenerate(seq)\n",
    "        degen.append(list(m))\n",
    "        allPositions.append(positions)\n",
    "        nchr.append([row['chr']] * len(m))\n",
    "        nchr = [item for sublist in nchr for item in sublist]\n",
    "        degen = [item for sublist in degen for item in sublist]\n",
    "        allPositions = [item for sublist in allPositions for item in sublist]\n",
    "        df = pd.DataFrame({'CHROM':nchr,'POS':allPositions,'degen':degen}) \n",
    "        df.to_csv('/home/jmurga/mkt/201903/rawData/humans/annotations/degeneracyHumanPositions.tab',mode='a',index=False,sep='\\t')\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "# nchr = [item for sublist in nchr for item in sublist]\n",
    "# degen = [item for sublist in degen for item in sublist]\n",
    "# allPositions = [item for sublist in allPositions for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foldPositions(x):\n",
    "    if('0' in x):\n",
    "        return('0fold')\n",
    "    elif('4' in x and '0' not in x and '2' not in x and '3' not in x):\n",
    "        return('4fold')\n",
    "    elif('2' in x and '0' not in x and '4' not in x and '3' not in x):\n",
    "        return('2fold')\n",
    "    elif('2' not in x and '0' not in x and '4' not in x) :\n",
    "        return('3fold')\n",
    "    else:\n",
    "        return(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/jmurga/mkt/201903/rawData/humans/annotations/degeneracyHumanPositions.tab',sep='\\t')\n",
    "    \n",
    "chrList = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,'X','Y']\n",
    "import time\n",
    "for nchr in chrList:\n",
    "    start_time = time.time()\n",
    "    print('chr' + str(nchr))\n",
    "    tmp = df[df['CHROM'] == 'chr' + str(nchr)]\n",
    "    tmp['POS'] = tmp['POS'].astype(int)\n",
    "#     tmp = tmp.groupby(['POS'])['degen'].apply(lambda x: ','.join(x)).reset_index()\n",
    "    tmp = tmp.groupby(['CHROM','POS']).agg({'degen':','.join}).reset_index()\n",
    "    tmp['type'] = np.nan\n",
    "    tmp['type'] = tmp['degen'].apply(foldPositions)\n",
    "    tmp = tmp[(tmp['type']=='0fold') | (tmp['type']=='4fold')]   \n",
    "    tmp = tmp.sort_values('POS')\n",
    "    tmp.to_csv(DATA + '/annotations/zeroFourFoldPositions.tab',header=False,index=False,mode='a',sep='\\t')\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "#     tmp.to_csv('/home/jmurga/mkt/201903/rawData/humans/annotations/degeneracyHumanPositions.tab',mode='a',index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning positions degenerancy based on most constrain posibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T09:23:40.180883Z",
     "start_time": "2019-02-25T09:23:21.067990Z"
    }
   },
   "outputs": [],
   "source": [
    "# degenerancyPositions = pd.read_csv(DATA + '/annotations/degeneracyHumanPositions.tab',sep='\\t',header=0)\n",
    "# degenerancyPositions['type'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# def foldPositions(x):\n",
    "#     if('0' in x):\n",
    "#         return('0fold')\n",
    "#     elif('4' in x and '0' not in x and '2' not in x and '3' not in x):\n",
    "#         return('4fold')\n",
    "#     elif('2' in x and '0' not in x and '4' not in x and '3' not in x):\n",
    "#         return('2fold')\n",
    "#     elif('2' not in x and '0' not in x and '4' not in x) :\n",
    "#         return('3fold')\n",
    "#     else:\n",
    "#         return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degenerancyPositions['type'] = degenerancyPositions['degen'].apply(foldPositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = degenerancyPositions[(degenerancyPositions['type']=='0fold') | (degenerancyPositions['type']=='4fold')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# degenerancyPositions.to_csv(DATA + '/annotations/zeroFourFoldPositions.tab',header=True,index=False,sep='\\t')\n",
    "# df.to_hdf(DATA + '/annotations/zeroFourFoldPositions.h5','degenerancy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Derived Allele Frequency and Divergence file by populations and type of site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-20T09:29:16.820939Z",
     "start_time": "2019-02-20T09:29:16.809010Z"
    },
    "heading_collapsed": true,
    "scrolled": true
   },
   "source": [
    "#### Extracting mi and m0 position by largest transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0 ,sep='\\t')\n",
    "cds = pd.read_csv(DATA + '/annotations/cdsCoordinates.tab',header = 0 ,sep='\\t')\n",
    "cds = cds.loc[cds.reset_index().groupby(['chr','id'])['transcriptSize'].idxmax()].reset_index(drop=True)\n",
    "cds = pd.merge(dfGenes,cds,on=['chr','id'])\n",
    "degeneratePositions =  pd.read_csv(DATA + '/annotations/zeroFourFoldPositions.tab',sep='\\t',header=None,names=['CHROM','POS','degen','type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "for nchr in degeneratePositions['CHROM'].unique():\n",
    "    print(nchr)\n",
    "    subsetDegen = degeneratePositions[degeneratePositions['CHROM']==nchr]\n",
    "    \n",
    "    for index, row in cds[cds['CHROM']==nchr].iterrows():\n",
    "        # Rewrite file each execution\n",
    "        degen = []\n",
    "        allPositions = []\n",
    "        nchrL = []\n",
    "        start_time = time.time()\n",
    "        print(index,row['id'])\n",
    "    #     chrPositions = degeneratePositions[degeneratePositions['CHROM']==row['chr']]\n",
    "        chrFile = px.Fasta('/home/jmurga/mkt/201903/rawData/humans/fastas/ref/' + row['chr'] +'.fa',sequence_always_upper=True)\n",
    "        # Convert CDS list into numeric array\n",
    "        coordinates = np.array(row['coordinates'].split(',')).astype(int).tolist()\n",
    "        coordinates =  [coordinates[i:i+2] for i in range(0, len(coordinates), 2)]\n",
    "        # Extract all CDS positions in a list in order to merge with degenerate sequences (same length -> same index)\n",
    "        positions=[]\n",
    "        for i in range(0,len(coordinates),1):\n",
    "            positions.append(list(range(coordinates[i][0],coordinates[i][1]+1)))  \n",
    "        positions = [item for sublist in positions for item in sublist]\n",
    "        # Extract cds sequences\n",
    "        seq = chrFile.get_spliced_seq(row['chr'], coordinates).seq\n",
    "        if(row['strand'] == '-'):\n",
    "            seq = reverseComplement(seq)\n",
    "            allPositions = allPositions[::-1]\n",
    "\n",
    "        if((len(seq)/3).is_integer() and seq[0:3]=='ATG'):\n",
    "            m = degenerate(seq)\n",
    "            degen.append(list(m))\n",
    "            allPositions.append(positions)\n",
    "            nchrL.append([row['chr']] * len(m))\n",
    "            # Create df containing allPositions and change type based on zeroFourFoldTable\n",
    "            nchrL = [item for sublist in nchrL for item in sublist]\n",
    "            degen = [item for sublist in degen for item in sublist]\n",
    "            allPositions = [item for sublist in allPositions for item in sublist]\n",
    "\n",
    "            df = pd.DataFrame({'CHROM':nchr,'POS':allPositions,'degen':degen})\n",
    "\n",
    "            tmp = pd.merge(subsetDegen[['CHROM','POS','type']],df,on=['CHROM','POS'],how='right')\n",
    "            counts = tmp['type'].value_counts()\n",
    "\n",
    "            if(counts.shape[0]<2 and '4fold' not in counts.index):\n",
    "                m0=0\n",
    "                mi=counts['0fold']\n",
    "\n",
    "            elif(counts.shape[0]<2 and '0fold' not in counts.index):\n",
    "                m0=counts['4fold']\n",
    "                mi=0\n",
    "            else:\n",
    "                m0=counts['4fold']\n",
    "                mi=counts['0fold']\n",
    "\n",
    "            data = pd.DataFrame({'id':row['id'],'mi':mi,'m0':m0},index=[0])\n",
    "            data.to_csv(DATA+'/annotations/refAnalizableSytes.tab',sep='\\t',header=False,index=False,mode='a')\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        else:\n",
    "            data = pd.DataFrame({'id':row['id'],'mi':0,'m0':0},index=[0])\n",
    "            data.to_csv(DATA+'/annotations/refAnalyzableSites.tab',sep='\\t',header=False,index=False,mode='a')\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:01:55.467605Z",
     "start_time": "2019-02-28T18:01:53.659003Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pops = ['ACB','ASW','BEB','CDX','CEU','CHB','CHS','CLM','ESN','FIN','GBR','GIH','GWD','IBS','ITU','JPT','KHV','LWK','MSL','MXL','PEL','PJL','PUR','STU','TSI','YRI']\n",
    "refAnalizableSites = pd.read_csv(DATA+'/annotations/refAnalyzableSites.tab',sep='\\t',header=None,names=['id','mi','m0'])\n",
    "\n",
    "totalFoldPositionsByPop = pd.DataFrame()\n",
    "for p in pops:\n",
    "    print(p)\n",
    "    refAnalizableSites['pop'] = p\n",
    "    \n",
    "    totalFoldPositionsByPop = totalFoldPositionsByPop.append(refAnalizableSites)\n",
    "\n",
    "totalFoldPositionsByPop = totalFoldPositionsByPop.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polymorphism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Manual recode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract coordinates from largest transcript to estimate allele frequency from variant data and merge with precalculated types of sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:31:06.565806Z",
     "start_time": "2019-03-01T17:30:54.493100Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0 ,sep='\\t')\n",
    "cds = pd.read_csv(DATA + '/annotations/cdsToExtract.bed',header = 0 ,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-01T17:31:06.769554Z",
     "start_time": "2019-03-01T17:31:06.704847Z"
    }
   },
   "outputs": [],
   "source": [
    "cds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T09:50:04.390944Z",
     "start_time": "2019-03-06T09:50:03.132598Z"
    }
   },
   "outputs": [],
   "source": [
    "!python /home/jmurga/mkt/201903/scripts/src/sfsFromVcf.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/jmurga/mkt/201903/scripts/src/sfsFromVcf.py --data gencodeGenesCleaned.tab --vcf 1000GP --populations Phase3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtract low quality positions from variants using bedtools intersect and 1000GP pilot mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersectBed -a <(awk '{print $1\"\\t\"$2-1\"\\t\"$2\"\\t\"$3\"\\t\"$4\"\\t\"$5\"\\t\"$6\"\\t\"$7\"\\t\"$8\"\\t\"$9\"\\t\"$10}' manualRawFrequencies.tab) -b <(sed 's/chr//g' /data/shared/1000GP/Masks/20141020.pilot_mask.whole_genome.bed) | cut -f1,3,4,5,6,7,8,9,10,11 > manualRawFrequenciesMasked.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawFrequencies = pd.read_csv(DATA + '/alleleFrequencies/manualRawFrequenciesMasked.tab',header=None,sep='\\t')\n",
    "rawFrequencies.columns = ['CHROM','POS','REF','ALT','AA','AC','AN','DAF','pop','id']\n",
    "rawFrequencies.to_hdf(DATA + '/alleleFrequencies/manualRawFrequenciesMasked.h5','variants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T09:23:13.851610Z",
     "start_time": "2019-02-27T09:23:13.847147Z"
    }
   },
   "source": [
    "##### SFS, Pi and P0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:03:09.272253Z",
     "start_time": "2019-02-28T17:02:52.703572Z"
    }
   },
   "outputs": [],
   "source": [
    "%time pol = pd.read_hdf('/home/jmurga/mkt/201903/rawData/humans/alleleFrequencies/manualRawFrequenciesMasked.h5') \n",
    "pol = pol[(pol['AC']!=0) & (pol['AC']!=pol['AN'])]\n",
    "pol = pol[(pol['AA']!='.') & (pol['AA']!='N') & (pol['AA']!='-')].dropna()\n",
    "# pol = pol[(pol['CHROM']==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:06:45.192002Z",
     "start_time": "2019-02-28T17:06:45.142946Z"
    }
   },
   "outputs": [],
   "source": [
    "pol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:31:36.007773Z",
     "start_time": "2019-02-26T09:31:36.003592Z"
    }
   },
   "source": [
    "Checking positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:08:45.278645Z",
     "start_time": "2019-02-28T17:07:44.899770Z"
    }
   },
   "outputs": [],
   "source": [
    "# positions = pd.read_csv(DATA + '/annotations/zeroFourFoldPositions.tab',header=0,sep='\\t')\n",
    "%time positions = pd.read_hdf(DATA + '/annotations/zeroFourFoldPositions.h5','positions')\n",
    "positions.columns = ['CHROM','POS','m','type']\n",
    "positions['CHROM'] = positions['CHROM'].apply(lambda x: re.sub('chr','',x))\n",
    "\n",
    "positions['CHROM']=positions['CHROM'].astype(str)\n",
    "positions['POS']=positions['POS'].astype(int)\n",
    "\n",
    "pol['CHROM']=pol['CHROM'].astype(str)\n",
    "pol['POS']=pol['POS'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:09:12.321784Z",
     "start_time": "2019-02-28T17:08:45.367389Z"
    }
   },
   "outputs": [],
   "source": [
    "pol = pd.merge(pol,positions,on=['CHROM','POS'],how='inner')\n",
    "pol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning by daf categories and creating new column from *type* to count number of occurrence by each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:09:12.525324Z",
     "start_time": "2019-02-28T17:09:12.325668Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = np.arange(0,1.05,0.05)\n",
    "labels = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1]\n",
    "# daf['categories'] = pd.cut(daf['freq'],bins=bins,labels=labels).astype(float).fillna(0)\n",
    "pol['categories'] = pd.cut(pol['DAF'],bins=bins,labels=labels)\n",
    "# Creating new column from type to count number of occurrence by category\n",
    "pol['count'] = pol['type']\n",
    "pol.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting total of sites grouping 0fold and 4fold categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:09:17.681592Z",
     "start_time": "2019-02-28T17:09:12.527827Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "totalSites = pol.groupby(['id','CHROM','pop','type'])['categories'].count().reset_index()\n",
    "totalSites = totalSites.pivot_table(index=['id','CHROM','pop'], columns=['type'],values='categories').reset_index()\n",
    "totalSites.columns = ['id','chr','pop','pi','p0']\n",
    "totalSites = totalSites.fillna(0)\n",
    "totalSites.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing Sites Frequency Spectrum to create a dataframe compatible with *iMKT R package*. Next steps include execute MKT over genes and populations using a modification of this packages. It was programmed to parse the SFS as string with dotComma separated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:18:48.858632Z",
     "start_time": "2019-02-28T17:09:17.684102Z"
    }
   },
   "outputs": [],
   "source": [
    "sfs = pol.loc[:,['id','pop','type','categories','count']].groupby(['id','pop','type','categories']).count().reset_index()\n",
    "sfs.columns = ['id','pop','type','categories','count']\n",
    "sfs['count'] = sfs['count'].fillna(0).astype(int)\n",
    "sfs = sfs.groupby(['id','pop','type'])['count'].apply(list).reset_index()\n",
    "sfs['count'] = sfs['count'].apply(lambda x:';'.join(map(str,x)))\n",
    "sfs = sfs.pivot_table(index=['id','pop'], columns=['type'],values='count',aggfunc=lambda x: ' '.join(x)).reset_index()\n",
    "sfs.columns = ['id','pop','daf0f','daf4f']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:18:48.876009Z",
     "start_time": "2019-02-28T17:18:48.861783Z"
    }
   },
   "outputs": [],
   "source": [
    "sfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:18:50.069607Z",
     "start_time": "2019-02-28T17:18:48.878235Z"
    }
   },
   "outputs": [],
   "source": [
    "daf = pd.merge(totalSites,sfs,on=['id','pop'])\n",
    "daf = daf.fillna(0)\n",
    "print(daf.shape)\n",
    "daf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:18:50.126983Z",
     "start_time": "2019-02-28T17:18:50.072616Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daf[daf['id']=='ENSG00000115850.9_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-13T15:31:08.598Z"
    }
   },
   "source": [
    "#### Divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting div sites from chimp alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T09:49:52.442647Z",
     "start_time": "2019-03-06T09:49:51.181312Z"
    }
   },
   "outputs": [],
   "source": [
    "!python /home/jmurga/mkt/201903/scripts/src/alleleFrequencyByPop.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/jmurga/mkt/201903/scripts/src/alleleFrequencyByPop.py --data gencodeGenesCleaned.tab --cds largestTranscriptCoordinates.h5 --VCF Alns --chromosomes all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtract low quality positions from variants using bedtools intersect and 1000GP pilot mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersectBed -a <(awk '{print $1\"\\t\"$2-1\"\\t\"$2\"\\t\"$3\"\\t\"$4\"\\t\"$5\"\\t\"$6\"\\t\"$7\"}' manualRawFrequencies.tab) -b <(sed 's/chr//g' /data/shared/1000GP/Masks/20141020.pilot_mask.whole_genome.bed) | cut -f1,3,4,5,6,7 > manualRawFrequenciesMasked.tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divPositions = pd.read(DATA + '/alleleFrequencies/manualRawFrequenciesMasked.tab',header=None,sep='\\t')\n",
    "divPositions.columns = ['CHROM','POS','REF','ALT','GT','id','transcript']\n",
    "divPositions.to_hdf(DATA + '/alleleFrequencies/manualRawFrequenciesMasked.h5','variants')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculating div sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:49:17.918526Z",
     "start_time": "2019-02-28T17:48:16.299176Z"
    }
   },
   "outputs": [],
   "source": [
    "fixedPol = pd.read_hdf('/home/jmurga/positiveSelectionHuman/201901/rawData/humans/alleleFrequencies/manualRawFrequenciesMasked.h5','variants')\n",
    "fixedPol['AA'] = fixedPol['AA'].str.upper()\n",
    "fixedPol = fixedPol[(fixedPol['AA']!='.') & (fixedPol['AA']!='N') & (fixedPol['AA']!='-')].dropna()\n",
    "fixedPol = fixedPol[(fixedPol['AC']==0) | (fixedPol['AC']==fixedPol['AN'])]\n",
    "fixedPol['CHROM'] = fixedPol['CHROM'].astype(str)\n",
    "fixedPol['POS'] = fixedPol['POS'].astype(int)\n",
    "fixedPol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:49:18.516329Z",
     "start_time": "2019-02-28T17:49:18.281288Z"
    }
   },
   "outputs": [],
   "source": [
    "div = pd.read_hdf('/home/jmurga/positiveSelectionHuman/201901/rawData/humans/alleleFrequencies/manualDivergenceVariantsMasked.h5')\n",
    "div = div[(div['ALT']!='N') & (div['ALT']!='')]\n",
    "div['CHROM'] = div['CHROM'].astype(str)\n",
    "div['POS'] = div['POS'].astype(int)\n",
    "div.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:50:26.807074Z",
     "start_time": "2019-02-28T17:49:18.870166Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "positions = pd.read_hdf(DATA + '/annotations/zeroFourFoldPositions.h5','positions')\n",
    "positions.columns = ['CHROM','POS','m','type']\n",
    "positions['CHROM'] = positions['CHROM'].astype(str)\n",
    "positions['POS'] = positions['POS'].astype(int)\n",
    "positions['CHROM'] = positions['CHROM'].apply(lambda x: re.sub('chr','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:50:52.064703Z",
     "start_time": "2019-02-28T17:50:27.167004Z"
    }
   },
   "outputs": [],
   "source": [
    "div = pd.merge(div,positions,on=['CHROM','POS'],how='inner')\n",
    "div.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate each pop and merge with divergent variants extract with VEP. Each iteration subset population and get only fixed variants in each population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:52:07.238976Z",
     "start_time": "2019-02-28T17:50:52.431404Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Subset all populations in dataframe\n",
    "pops = fixedPol['pop'].unique()\n",
    "\n",
    "# Empty df to append each population\n",
    "divSites = pd.DataFrame()\n",
    "\n",
    "for p in pops:\n",
    "    print(p)\n",
    "    # Subset population and fixed variants\n",
    "    fixedPolSubset = fixedPol[fixedPol['pop'] == p]\n",
    "\n",
    "    # Merging all fixed variants and posible divergent sites\n",
    "    divPol = pd.merge(div[['POS','CHROM','GT','id','type']],fixedPolSubset[['POS','CHROM','AC']],on=['CHROM','POS'],how='outer')\n",
    "    \n",
    "    # Extract and count real divergent sites     \n",
    "    divPol.loc[:,'d'] = np.nan\n",
    "    divPol.loc[:,'d'] = divPol[~divPol['GT'].isna()]['d'].fillna(1)\n",
    "    divPol = divPol[~divPol['d'].isna()]\n",
    "    \n",
    "    # Cleaning and grouping divergent site by id\n",
    "    tmp = divPol[['POS','id','type','d']]\n",
    "    tmp = tmp.groupby(['id','type'])['d'].count().reset_index()\n",
    "    tmp = tmp.pivot_table(index=['id'],columns=['type'],values='d').reset_index()\n",
    "    tmp.columns = ['id','di','d0']\n",
    "    tmp = tmp.fillna(0)\n",
    "    tmp['pop'] = p\n",
    "\n",
    "    # Append results to df by pop\n",
    "    divSites = divSites.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T17:52:07.755869Z",
     "start_time": "2019-02-28T17:52:07.621250Z"
    }
   },
   "outputs": [],
   "source": [
    "divSites[divSites['id']=='ENSG00000115850.9_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T16:45:32.477702Z",
     "start_time": "2019-02-05T16:45:32.453534Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "#### Merging Derived Allele Frequencies, divergency and total analyzed sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0 ,usecols=['id','chr'],sep='\\t') \n",
    "dfGenes['chr']=dfGenes['chr'].apply(lambda x: re.sub('chr','',x))\n",
    "pops = ['ACB','ASW','BEB','CDX','CEU','CHB','CHS','CLM','ESN','FIN','GBR','GIH','GWD','IBS','ITU','JPT','KHV','LWK','MSL','MXL','PEL','PJL','PUR','STU','TSI','YRI']\n",
    "\n",
    "ids = pd.DataFrame()\n",
    "for p in pops:\n",
    "    print(p)\n",
    "    dfGenes['pop'] = p\n",
    "    \n",
    "    ids = ids.append(dfGenes)\n",
    "\n",
    "ids = ids.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:14.076794Z",
     "start_time": "2019-02-28T18:02:13.209761Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfToMerge = pd.merge(daf,totalFoldPositionsByPop,on=['id','pop'],how='outer')\n",
    "dfToMerge['id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfToMerge = pd.merge(dfToMerge,ids,on=['chr','id','pop'],how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:18.373006Z",
     "start_time": "2019-02-28T18:02:15.433627Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "humanGenes = pd.merge(dfToMerge, divSites,on=['id','pop'],how='outer')\n",
    "humanGenes = humanGenes.sort_values(['chr','id','pop'])\n",
    "humanGenes[humanGenes['daf0f'].isna()].loc[:,'daf0f'] = '0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0'\n",
    "humanGenes[humanGenes['daf4f'].isna()].loc[:,'daf4f'] = '0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0'\n",
    "humanGenes['daf0f'] = humanGenes['daf0f'].fillna('0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0')\n",
    "humanGenes['daf4f'] = humanGenes['daf4f'].fillna('0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0')\n",
    "humanGenes = humanGenes.fillna(0)\n",
    "humanGenes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:19.856686Z",
     "start_time": "2019-02-28T18:02:19.431496Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfGenes = pd.read_csv(DATA + '/annotations/gencodeGenesCleaned.tab',header = 0 ,usecols=['id','name'],sep='\\t')\n",
    "humanGenes = pd.merge(humanGenes,dfGenes,on=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:21.912601Z",
     "start_time": "2019-02-28T18:02:21.880922Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "humanGenes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:24.170869Z",
     "start_time": "2019-02-28T18:02:23.758348Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dfRecomb = pd.read_csv(DATA + '/genesRecomb.tab',header = 0 ,sep='\\t')\n",
    "humanGenes = pd.merge(humanGenes,dfRecomb,on=['id'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:26.400297Z",
     "start_time": "2019-02-28T18:02:26.356547Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "humanGenes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-28T18:02:36.353963Z",
     "start_time": "2019-02-28T18:02:28.531173Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "humanGenes.to_csv('/home/jmurga/mkt/201903/rawData/humans/humanGenesPhase3Masked.tab',sep='\\t',index=False,header=True,na_rep=\"NA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
